{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f43b430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36a3a474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>Sex</th>\n",
       "      <th>L Aud-R Aud</th>\n",
       "      <th>L Aud-Striate</th>\n",
       "      <th>R Aud-Striate</th>\n",
       "      <th>L Aud-L DMN</th>\n",
       "      <th>R Aud-L DMN</th>\n",
       "      <th>Striate-L DMN</th>\n",
       "      <th>...</th>\n",
       "      <th>Broca-R Ant IPS</th>\n",
       "      <th>Sup Front S-R Ant IPS</th>\n",
       "      <th>R TPJ-R Ant IPS</th>\n",
       "      <th>R Pars Op-R Ant IPS</th>\n",
       "      <th>Cereb-R Ant IPS</th>\n",
       "      <th>Dors PCC-R Ant IPS</th>\n",
       "      <th>L Ins-R Ant IPS</th>\n",
       "      <th>Cing-R Ant IPS</th>\n",
       "      <th>R Ins-R Ant IPS</th>\n",
       "      <th>L Ant IPS-R Ant IPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>morphometry_A00007409</td>\n",
       "      <td>A00007409</td>\n",
       "      <td>No_Known_Disorder</td>\n",
       "      <td>male</td>\n",
       "      <td>0.852745</td>\n",
       "      <td>0.472408</td>\n",
       "      <td>0.438451</td>\n",
       "      <td>-0.151586</td>\n",
       "      <td>-0.175817</td>\n",
       "      <td>-0.088072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157520</td>\n",
       "      <td>0.111554</td>\n",
       "      <td>0.024794</td>\n",
       "      <td>0.074087</td>\n",
       "      <td>0.083605</td>\n",
       "      <td>0.332223</td>\n",
       "      <td>0.299678</td>\n",
       "      <td>0.378165</td>\n",
       "      <td>0.238186</td>\n",
       "      <td>0.633913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morphometry_A00031597</td>\n",
       "      <td>A00031597</td>\n",
       "      <td>Schizophrenia_Strict</td>\n",
       "      <td>male</td>\n",
       "      <td>0.748457</td>\n",
       "      <td>0.532091</td>\n",
       "      <td>0.617542</td>\n",
       "      <td>0.090878</td>\n",
       "      <td>0.043540</td>\n",
       "      <td>-0.036074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374588</td>\n",
       "      <td>0.340460</td>\n",
       "      <td>0.342494</td>\n",
       "      <td>0.249617</td>\n",
       "      <td>0.382124</td>\n",
       "      <td>0.604362</td>\n",
       "      <td>0.168657</td>\n",
       "      <td>0.284299</td>\n",
       "      <td>0.183674</td>\n",
       "      <td>0.626664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>morphometry_A00022500</td>\n",
       "      <td>A00022500</td>\n",
       "      <td>Schizophrenia_Strict</td>\n",
       "      <td>female</td>\n",
       "      <td>0.592125</td>\n",
       "      <td>0.036093</td>\n",
       "      <td>0.133537</td>\n",
       "      <td>0.082847</td>\n",
       "      <td>0.179051</td>\n",
       "      <td>0.314248</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253343</td>\n",
       "      <td>-0.049419</td>\n",
       "      <td>0.103218</td>\n",
       "      <td>-0.098405</td>\n",
       "      <td>-0.106043</td>\n",
       "      <td>0.359292</td>\n",
       "      <td>-0.283070</td>\n",
       "      <td>0.194902</td>\n",
       "      <td>-0.112684</td>\n",
       "      <td>0.582636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>morphometry_A00024953</td>\n",
       "      <td>A00024953</td>\n",
       "      <td>Schizophrenia_Strict</td>\n",
       "      <td>male</td>\n",
       "      <td>0.780837</td>\n",
       "      <td>0.354871</td>\n",
       "      <td>0.420179</td>\n",
       "      <td>0.144601</td>\n",
       "      <td>0.208352</td>\n",
       "      <td>0.168114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190040</td>\n",
       "      <td>-0.012739</td>\n",
       "      <td>-0.038590</td>\n",
       "      <td>0.150418</td>\n",
       "      <td>0.043712</td>\n",
       "      <td>0.165942</td>\n",
       "      <td>-0.003737</td>\n",
       "      <td>0.316817</td>\n",
       "      <td>-0.003129</td>\n",
       "      <td>0.633039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>morphometry_A00001251</td>\n",
       "      <td>A00001251</td>\n",
       "      <td>Schizophrenia_Strict</td>\n",
       "      <td>male</td>\n",
       "      <td>0.447026</td>\n",
       "      <td>-0.024045</td>\n",
       "      <td>0.432331</td>\n",
       "      <td>-0.247530</td>\n",
       "      <td>0.113947</td>\n",
       "      <td>0.412405</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240672</td>\n",
       "      <td>0.271395</td>\n",
       "      <td>-0.054881</td>\n",
       "      <td>0.044233</td>\n",
       "      <td>0.063376</td>\n",
       "      <td>0.387130</td>\n",
       "      <td>0.145573</td>\n",
       "      <td>0.396055</td>\n",
       "      <td>0.112810</td>\n",
       "      <td>0.532662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 745 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file         ID                target     Sex  \\\n",
       "0  morphometry_A00007409  A00007409     No_Known_Disorder    male   \n",
       "1  morphometry_A00031597  A00031597  Schizophrenia_Strict    male   \n",
       "2  morphometry_A00022500  A00022500  Schizophrenia_Strict  female   \n",
       "3  morphometry_A00024953  A00024953  Schizophrenia_Strict    male   \n",
       "4  morphometry_A00001251  A00001251  Schizophrenia_Strict    male   \n",
       "\n",
       "   L Aud-R Aud  L Aud-Striate  R Aud-Striate  L Aud-L DMN  R Aud-L DMN  \\\n",
       "0     0.852745       0.472408       0.438451    -0.151586    -0.175817   \n",
       "1     0.748457       0.532091       0.617542     0.090878     0.043540   \n",
       "2     0.592125       0.036093       0.133537     0.082847     0.179051   \n",
       "3     0.780837       0.354871       0.420179     0.144601     0.208352   \n",
       "4     0.447026      -0.024045       0.432331    -0.247530     0.113947   \n",
       "\n",
       "   Striate-L DMN  ...  Broca-R Ant IPS  Sup Front S-R Ant IPS  \\\n",
       "0      -0.088072  ...         0.157520               0.111554   \n",
       "1      -0.036074  ...         0.374588               0.340460   \n",
       "2       0.314248  ...        -0.253343              -0.049419   \n",
       "3       0.168114  ...         0.190040              -0.012739   \n",
       "4       0.412405  ...        -0.240672               0.271395   \n",
       "\n",
       "   R TPJ-R Ant IPS  R Pars Op-R Ant IPS  Cereb-R Ant IPS  Dors PCC-R Ant IPS  \\\n",
       "0         0.024794             0.074087         0.083605            0.332223   \n",
       "1         0.342494             0.249617         0.382124            0.604362   \n",
       "2         0.103218            -0.098405        -0.106043            0.359292   \n",
       "3        -0.038590             0.150418         0.043712            0.165942   \n",
       "4        -0.054881             0.044233         0.063376            0.387130   \n",
       "\n",
       "   L Ins-R Ant IPS  Cing-R Ant IPS  R Ins-R Ant IPS  L Ant IPS-R Ant IPS  \n",
       "0         0.299678        0.378165         0.238186             0.633913  \n",
       "1         0.168657        0.284299         0.183674             0.626664  \n",
       "2        -0.283070        0.194902        -0.112684             0.582636  \n",
       "3        -0.003737        0.316817        -0.003129             0.633039  \n",
       "4         0.145573        0.396055         0.112810             0.532662  \n",
       "\n",
       "[5 rows x 745 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./func_conn.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d291e552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([col for col in data.columns if 'L Aud' in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af554fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([col for col in data.columns if 'Striate' in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc5fb39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertices_names = set()\n",
    "[[vertices_names.add(val) for val in col.split('-')] for col in data.columns[4:]];\n",
    "len(vertices_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d68cd7f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "75\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "for vert in vertices_names:\n",
    "    print(len([col for col in data.columns if vert in col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e006f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connectivity_mat = np.zeros((len(vertices_names), len(vertices_names)))\n",
    "names_map = {val: i for i, val in enumerate(vertices_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbec2bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_0 = pd.DataFrame(data.iloc[0]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b8b09e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjmat(patient):\n",
    "    connectivity_mat = np.zeros((len(vertices_names), len(vertices_names)))\n",
    "\n",
    "    for name1 in names_map.keys():\n",
    "        for name2 in names_map.keys():\n",
    "            col_name = f'{name1}-{name2}'\n",
    "            \n",
    "            connectivity_mat[names_map[name1]][names_map[name2]] = patient[col_name] if col_name in patient.columns else 0.0\n",
    "    return connectivity_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11e3ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "connectivity_mat = get_adjmat(patient_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a507decf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9c00a7a730>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(connectivity_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "05b00742",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/IBGNN/datasets/Schiza.txt', 'w') as f:\n",
    "    for name in names_map.values():\n",
    "        f.write(f'0\\t0\\t0\\t{name}\\t0\\tregion_name\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e439743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ffe1af5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No_Known_Disorder', 'Schizoaffective', 'Schizophrenia_Strict'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50480dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schizastrict = data.drop(data[data['target'] == 'Schizoaffective'].index, axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1093ecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_schizastrict = data_schizastrict['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "215efd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_bin = [1. if ('Schizo' in l) else 0. for l in labels_schizastrict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb074aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "connectivity_data = np.asarray(list([get_adjmat(pd.DataFrame(pat).T) for pat in data_schizastrict.to_numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "898486f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 39, 39)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connectivity_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "226a47cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat, loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82b0d6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat('/home/IBGNN/datasets/schiza.mat', {'label': labels_bin, 'dti': connectivity_data.T})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1dddb2e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file Platform: posix, Created on: Mon Oct 17 13:19:02 2022',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'label': array([[0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
       "         0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,\n",
       "         1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "         1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "         1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "         0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "         0., 0., 1., 0., 0., 0., 1., 0.]]),\n",
       " 'dti': array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadmat('/home/IBGNN/datasets/schiza.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4731fba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t0\t0\t0\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t1\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t2\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t3\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t4\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t5\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t6\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t7\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t8\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t9\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t10\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t11\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t12\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t13\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t14\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t15\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t16\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t17\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t18\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t19\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t20\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t21\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t22\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t23\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t24\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t25\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t26\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t27\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t28\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t29\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t30\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t31\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t32\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t33\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t34\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t35\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t36\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t37\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t38\t0\tregion_name\n",
      "\n",
      "[[0.0, 0.0, 0.0, 0, 'region_name\\n'], [0.0, 0.0, 0.0, 1, 'region_name\\n'], [0.0, 0.0, 0.0, 2, 'region_name\\n'], [0.0, 0.0, 0.0, 3, 'region_name\\n'], [0.0, 0.0, 0.0, 4, 'region_name\\n'], [0.0, 0.0, 0.0, 5, 'region_name\\n'], [0.0, 0.0, 0.0, 6, 'region_name\\n'], [0.0, 0.0, 0.0, 7, 'region_name\\n'], [0.0, 0.0, 0.0, 8, 'region_name\\n'], [0.0, 0.0, 0.0, 9, 'region_name\\n'], [0.0, 0.0, 0.0, 10, 'region_name\\n'], [0.0, 0.0, 0.0, 11, 'region_name\\n'], [0.0, 0.0, 0.0, 12, 'region_name\\n'], [0.0, 0.0, 0.0, 13, 'region_name\\n'], [0.0, 0.0, 0.0, 14, 'region_name\\n'], [0.0, 0.0, 0.0, 15, 'region_name\\n'], [0.0, 0.0, 0.0, 16, 'region_name\\n'], [0.0, 0.0, 0.0, 17, 'region_name\\n'], [0.0, 0.0, 0.0, 18, 'region_name\\n'], [0.0, 0.0, 0.0, 19, 'region_name\\n'], [0.0, 0.0, 0.0, 20, 'region_name\\n'], [0.0, 0.0, 0.0, 21, 'region_name\\n'], [0.0, 0.0, 0.0, 22, 'region_name\\n'], [0.0, 0.0, 0.0, 23, 'region_name\\n'], [0.0, 0.0, 0.0, 24, 'region_name\\n'], [0.0, 0.0, 0.0, 25, 'region_name\\n'], [0.0, 0.0, 0.0, 26, 'region_name\\n'], [0.0, 0.0, 0.0, 27, 'region_name\\n'], [0.0, 0.0, 0.0, 28, 'region_name\\n'], [0.0, 0.0, 0.0, 29, 'region_name\\n'], [0.0, 0.0, 0.0, 30, 'region_name\\n'], [0.0, 0.0, 0.0, 31, 'region_name\\n'], [0.0, 0.0, 0.0, 32, 'region_name\\n'], [0.0, 0.0, 0.0, 33, 'region_name\\n'], [0.0, 0.0, 0.0, 34, 'region_name\\n'], [0.0, 0.0, 0.0, 35, 'region_name\\n'], [0.0, 0.0, 0.0, 36, 'region_name\\n'], [0.0, 0.0, 0.0, 37, 'region_name\\n'], [0.0, 0.0, 0.0, 38, 'region_name\\n']]\n",
      "0\t0\t0\t0\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t1\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t2\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t3\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t4\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t5\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t6\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t7\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t8\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t9\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t10\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t11\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t12\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t13\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t14\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t15\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t16\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t17\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t18\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t19\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t20\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t21\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t22\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t23\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t24\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t25\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t26\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t27\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t28\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t29\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t30\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t31\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t32\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t33\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t34\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t35\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t36\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t37\t0\tregion_name\n",
      "\n",
      "0\t0\t0\t38\t0\tregion_name\n",
      "\n",
      "seed for seed_everything(): 258045\n",
      "seed for seed_everything(): 485267\n",
      "/root/anaconda3/lib/python3.9/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "(Initial Train) | Epoch=000, loss=0.8235, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=001, loss=0.6403, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=002, loss=0.4639, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=003, loss=0.2913, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=004, loss=0.1136, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=005, loss=0.0606, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=006, loss=0.0645, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=007, loss=0.0525, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=008, loss=0.0490, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=009, loss=0.0485, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=010, loss=0.0488, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=011, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=012, loss=0.0480, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=013, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=014, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=015, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=016, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=017, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=018, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=019, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train Epoch 19), test_micro=50.00, test_macro=33.33, test_auc=50.00\n",
      "\n",
      "(Initial Train) | Epoch=020, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=021, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=022, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=023, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=024, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=025, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=026, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=027, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=028, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=029, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=030, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=031, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=032, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=033, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=034, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=035, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=036, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=037, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=038, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=039, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train Epoch 39), test_micro=50.00, test_macro=33.33, test_auc=50.00\n",
      "\n",
      "(Initial Train) | Epoch=040, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=041, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=042, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=043, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=044, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=045, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=046, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=047, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=048, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=049, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=050, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=051, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=052, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=053, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=054, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=055, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=056, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=057, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=058, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=059, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train Epoch 59), test_micro=50.00, test_macro=33.33, test_auc=50.00\n",
      "\n",
      "(Initial Train) | Epoch=060, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=061, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=062, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=063, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=064, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=065, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=066, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=067, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=068, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=069, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=070, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=071, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=072, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=073, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=074, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=075, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=076, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=077, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=078, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=079, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train Epoch 79), test_micro=50.00, test_macro=33.33, test_auc=50.00\n",
      "\n",
      "(Initial Train) | Epoch=080, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=081, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=082, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=083, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=084, loss=0.0484, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=085, loss=0.0484, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=086, loss=0.0484, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=087, loss=0.0484, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=088, loss=0.0484, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=089, loss=0.0484, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=090, loss=0.0484, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=091, loss=0.0484, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=092, loss=0.0484, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=093, loss=0.0484, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=094, loss=0.0484, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=095, loss=0.0484, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=096, loss=0.0484, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=097, loss=0.0484, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=098, loss=0.0484, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=099, loss=0.0484, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train Epoch 99), test_micro=50.00, test_macro=33.33, test_auc=50.00\n",
      "\n",
      "(Initial Performance Last Epoch) | test_micro=50.00, test_macro=33.33, test_auc=50.00\n",
      "/root/anaconda3/lib/python3.9/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "Explainer Training: 100%|█████████████████████| 100/100 [00:51<00:00,  1.94it/s](Explainer Train) | Epoch=100, loss=30.3279\n",
      "Explainer Training: 100%|█████████████████████| 100/100 [00:51<00:00,  1.92it/s]\n",
      "(Tuning Train) | Epoch=000, loss=0.0720, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=001, loss=0.0521, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=002, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=003, loss=0.0496, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=004, loss=0.0502, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=005, loss=0.0514, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=006, loss=0.0476, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=007, loss=0.0496, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=008, loss=0.0517, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=009, loss=0.0494, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=010, loss=0.0479, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=011, loss=0.0489, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=012, loss=0.0507, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=013, loss=0.0554, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=014, loss=0.0528, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=015, loss=0.0511, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=016, loss=0.0514, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=017, loss=0.0487, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=018, loss=0.0505, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=019, loss=0.0508, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train Epoch 19), test_micro=50.00, test_macro=33.33, test_auc=50.00\n",
      "\n",
      "(Tuning Train) | Epoch=020, loss=0.0497, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=021, loss=0.0478, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=022, loss=0.0487, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=023, loss=0.0514, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=024, loss=0.0476, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=025, loss=0.0502, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=026, loss=0.0485, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=027, loss=0.0480, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=028, loss=0.0503, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=029, loss=0.0525, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=030, loss=0.0544, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=031, loss=0.0508, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=032, loss=0.0479, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=033, loss=0.0511, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=034, loss=0.0495, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=035, loss=0.0498, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=036, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=037, loss=0.0493, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=038, loss=0.0501, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=039, loss=0.0500, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train Epoch 39), test_micro=50.00, test_macro=33.33, test_auc=50.00\n",
      "\n",
      "(Tuning Train) | Epoch=040, loss=0.0490, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=041, loss=0.0496, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=042, loss=0.0475, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=043, loss=0.0496, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=044, loss=0.0496, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=045, loss=0.0479, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=046, loss=0.0486, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=047, loss=0.0488, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=048, loss=0.0494, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=049, loss=0.0493, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=050, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=051, loss=0.0487, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=052, loss=0.0490, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=053, loss=0.0501, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=054, loss=0.0524, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=055, loss=0.0479, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=056, loss=0.0493, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=057, loss=0.0494, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=058, loss=0.0487, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=059, loss=0.0477, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train Epoch 59), test_micro=50.00, test_macro=33.33, test_auc=50.00\n",
      "\n",
      "(Tuning Train) | Epoch=060, loss=0.0491, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=061, loss=0.0507, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=062, loss=0.0503, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=063, loss=0.0495, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=064, loss=0.0504, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=065, loss=0.0472, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=066, loss=0.0490, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=067, loss=0.0484, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=068, loss=0.0490, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=069, loss=0.0500, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=070, loss=0.0489, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=071, loss=0.0474, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=072, loss=0.0503, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=073, loss=0.0498, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=074, loss=0.0509, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=075, loss=0.0519, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=076, loss=0.0488, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=077, loss=0.0498, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=078, loss=0.0503, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=079, loss=0.0497, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train Epoch 79), test_micro=50.00, test_macro=33.33, test_auc=50.00\n",
      "\n",
      "(Tuning Train) | Epoch=080, loss=0.0475, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=081, loss=0.0497, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=082, loss=0.0484, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=083, loss=0.0486, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=084, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=085, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=086, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=087, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=088, loss=0.0492, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=089, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=090, loss=0.0489, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=091, loss=0.0508, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=092, loss=0.0538, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=093, loss=0.0514, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=094, loss=0.0521, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=095, loss=0.0507, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=096, loss=0.0504, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=097, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=098, loss=0.0484, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train) | Epoch=099, loss=0.0482, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Tuning Train Epoch 99), test_micro=50.00, test_macro=33.33, test_auc=50.00\n",
      "\n",
      "(Tuning Performance Last Epoch) | explainer_test_micro=50.00, explainer_test_macro=33.33, explainer_test_auc=50.00\n",
      "/root/anaconda3/lib/python3.9/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "(Initial Train) | Epoch=000, loss=0.8342, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=001, loss=0.7497, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=002, loss=0.6724, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=003, loss=0.5939, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=004, loss=0.5067, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=005, loss=0.4064, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=006, loss=0.2884, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=007, loss=0.1489, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=008, loss=0.0546, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=009, loss=0.0659, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=010, loss=0.0508, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=011, loss=0.0503, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=012, loss=0.0479, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=013, loss=0.0486, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=014, loss=0.0483, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=015, loss=0.0480, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=016, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=017, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=018, loss=0.0480, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=019, loss=0.0480, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train Epoch 19), test_micro=50.00, test_macro=33.33, test_auc=50.00\n",
      "\n",
      "(Initial Train) | Epoch=020, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=021, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=022, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=023, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=024, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=025, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=026, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=027, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=028, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=029, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=030, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=031, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=032, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=033, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=034, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=035, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=036, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=037, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=038, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=039, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train Epoch 39), test_micro=50.00, test_macro=33.33, test_auc=50.00\n",
      "\n",
      "(Initial Train) | Epoch=040, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=041, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=042, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=043, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=044, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=045, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=046, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=047, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=048, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=049, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=050, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=051, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=052, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=053, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=054, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=055, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=056, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=057, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=058, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=059, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train Epoch 59), test_micro=50.00, test_macro=33.33, test_auc=50.00\n",
      "\n",
      "(Initial Train) | Epoch=060, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=061, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=062, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=063, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=064, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=065, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=066, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=067, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=068, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=069, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=070, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=071, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=072, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n",
      "(Initial Train) | Epoch=073, loss=0.0481, \n",
      "train_micro=50.00, train_macro=33.33, train_auc=50.00\n"
     ]
    }
   ],
   "source": [
    "!cd /home/IBGNN && python main_explainer.py --dataset_name=schiza --explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6cb773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
